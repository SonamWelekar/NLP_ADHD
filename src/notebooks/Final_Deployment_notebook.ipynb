{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import sklearn\n",
    "import os\n",
    "\n",
    "import shutil\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting path for importing required functions for data processing\n",
    "\n",
    "sys.path.append(\"/home/jupyter/sonam/adhd_nlp/final_notebook_folder/data_processing\")\n",
    "sys.path.append(\"/home/jupyter/sonam/adhd_nlp/final_notebook_folder/data_processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions required for data processing\n",
    "\n",
    "import final_process_text\n",
    "import final_transform_textfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('max_colwidth', 300)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using simpletransformer ai library\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_df = pd.read_csv('/home/jupyter/data/cohort_2to6/notes-other-adhd-wc-visits-2021-10-19.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deploy_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values\n",
    "\n",
    "deploy_df['note_des'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_df = deploy_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples in deployment set are  1020\n"
     ]
    }
   ],
   "source": [
    "#deploy_df.shape\n",
    "deploy_df = deploy_df.reset_index(drop=True)\n",
    "print(\"The number of samples in deployment set are \",deploy_df.shape[0])\n",
    "#deploy_df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_df['extractText'] = deploy_df['note_des'].apply(lambda x: final_process_text.sectionize(x)[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_df['extractText'] = deploy_df['extractText'].apply(lambda x: final_process_text.clean_text(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_df= deploy_df.loc[:, ['ANON_ID','PAT_ENC_ID_JITTERED','extractText']]\\\n",
    "       .rename(columns = {'extractText':'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final deploy_df looks like below.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ANON_ID                 int64\n",
       "PAT_ENC_ID_JITTERED     int64\n",
       "text                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#deploy_df.tail(2)\n",
    "print(\"The final deploy_df looks like below.\")\n",
    "deploy_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading saved model weights and getting results for deployment set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading saved weights from the training  for defining the model\n",
    "model = ClassificationModel(\"bert\", \"./final_biobert_output_dir_new_cohort\",use_cuda = True, num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39126a847fee4f5aab04f86e6bab8e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1020.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08dadfa2f2a3495584b40d3b3f4295a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting labels and probablities for 1020 samples and adding in deploy_df as columns\n",
    "predictions, probabilities = model.predict(deploy_df['text'].tolist())\n",
    "\n",
    "deploy_df['predictions'] = predictions\n",
    "deploy_df['probabilities'] = [x[1] for x in np.array([softmax(element) for element in probabilities])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The deploy_df dataframe looks like below now.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ANON_ID                  int64\n",
       "PAT_ENC_ID_JITTERED      int64\n",
       "text                    object\n",
       "predictions              int64\n",
       "probabilities          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#deploy_df.tail(2)\n",
    "print(\"The deploy_df dataframe looks like below now.\")\n",
    "deploy_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_pred_prob = deploy_df['probabilities']\n",
    "\n",
    "# threshold value obtained from Final_423_Deployment_notebook_new_cohort.ipnyb\n",
    "threshold_final = 0.001842"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to obtain the prediction using threshold value for probabilities\n",
    "def pred_label(threshold_final, pred_prob):\n",
    "    \n",
    "    pred_label = (pred_prob >= threshold_final)\n",
    "\n",
    "    pred_label = pred_label.values.astype(int)\n",
    "    \n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passing threshold and probabilities to get prediction according to threshold\n",
    "pred_prob_arr = pred_label(threshold_final, deploy_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating predictions column with predictions obtained after using threshold values for probabilities\n",
    "deploy_df['predictions']= pred_prob_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Checking Results for predictions with threshold and without threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Threshold:\n",
      "predicted 0: 975\n",
      "predicted 1: 45\n"
     ]
    }
   ],
   "source": [
    "type(predictions)\n",
    "print(\"Without Threshold:\")\n",
    "print(\"predicted 0:\", predictions.count(0))\n",
    "print(\"predicted 1:\", predictions.count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Threshold of 0.001842:\n",
      "predicted 0: 970\n",
      "predicted 1: 50\n"
     ]
    }
   ],
   "source": [
    "pred_prob_label_list =deploy_df['predictions'].tolist()\n",
    "\n",
    "print(\"With Threshold of 0.001842:\")\n",
    "print(\"predicted 0:\", pred_prob_label_list.count(0))\n",
    "print(\"predicted 1:\", pred_prob_label_list.count(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the file having \"ANNON_ID\", \"ENC_ID\",text\" and \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output csv file is saved with predictions for the deployment notes.\n"
     ]
    }
   ],
   "source": [
    "header = [\"ANON_ID\", \"PAT_ENC_ID_JITTERED\",\"predictions\", \"text\"]\n",
    "deploy_df.to_csv('/home/jupyter/sonam/final_result_files/final_biobert_output_1020notes.csv', columns = header, index=False)\n",
    "print(\"The output csv file is saved with predictions for the deployment notes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1020, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading output_csv file to see if its saved correctly\n",
    "\n",
    "deploy_results =pd.read_csv('/home/jupyter/sonam/final_result_files/final_biobert_output_1020notes.csv') \n",
    "deploy_results.shape"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
