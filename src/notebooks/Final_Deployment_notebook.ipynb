{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import sklearn\n",
    "import os\n",
    "\n",
    "import shutil\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting path for importing required functions for data processing\n",
    "\n",
    "sys.path.append(\"/home/jupyter/sonam/adhd_nlp/final_notebook_folder/data_processing\")\n",
    "sys.path.append(\"/home/jupyter/sonam/adhd_nlp/final_notebook_folder/data_processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions required for data processing\n",
    "\n",
    "import final_process_text\n",
    "import final_transform_textfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('max_colwidth', 300)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using simpletransformer ai library\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_df = pd.read_csv('/home/jupyter/data/cohort_2to6/notes-other-adhd-wc-visits-2021-10-19.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_df = deploy_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deploy_df.shape\n",
    "deploy_df = deploy_df.reset_index(drop=True)\n",
    "print(\"The number of samples in deployment set are \",deploy_df.shape[0])\n",
    "#deploy_df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_df['extractText'] = deploy_df['note_des'].apply(lambda x: final_process_text.sectionize(x)[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_df['extractText'] = deploy_df['extractText'].apply(lambda x: final_process_text.clean_text(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_df= deploy_df.loc[:, ['ANON_ID','PAT_ENC_ID_JITTERED','extractText']]\\\n",
    "       .rename(columns = {'extractText':'text'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading saved model weights and getting results for deployment set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading saved weights from the training  for defining the model\n",
    "model = ClassificationModel(\"bert\", \"./final_biobert_output_dir_new_cohort\",use_cuda = True, num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting labels and probablities for 1020 samples and adding in deploy_df as columns\n",
    "predictions, probabilities = model.predict(deploy_df['text'].tolist())\n",
    "\n",
    "deploy_df['predictions'] = predictions\n",
    "deploy_df['probabilities'] = [x[1] for x in np.array([softmax(element) for element in probabilities])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_pred_prob = deploy_df['probabilities']\n",
    "\n",
    "# threshold value obtained from Final_423_Deployment_notebook_new_cohort.ipnyb\n",
    "threshold_final = 0.001842"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to obtain the prediction using threshold value for probabilities\n",
    "def pred_label(threshold_final, pred_prob):\n",
    "    \n",
    "    pred_label = (pred_prob >= threshold_final)\n",
    "\n",
    "    pred_label = pred_label.values.astype(int)\n",
    "    \n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passing threshold and probabilities to get prediction according to threshold\n",
    "pred_prob_arr = pred_label(threshold_final, deploy_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating predictions column with predictions obtained after using threshold values for probabilities\n",
    "deploy_df['predictions']= pred_prob_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Checking Results for predictions with threshold and without threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(predictions)\n",
    "print(\"Without Threshold:\")\n",
    "print(\"predicted 0:\", predictions.count(0))\n",
    "print(\"predicted 1:\", predictions.count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_label_list =deploy_df['predictions'].tolist()\n",
    "\n",
    "print(\"With Threshold of 0.001842:\")\n",
    "print(\"predicted 0:\", pred_prob_label_list.count(0))\n",
    "print(\"predicted 1:\", pred_prob_label_list.count(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the file having \"ANNON_ID\", \"ENC_ID\",text\" and \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"ANON_ID\", \"PAT_ENC_ID_JITTERED\",\"predictions\", \"text\"]\n",
    "deploy_df.to_csv('/home/jupyter/sonam/final_result_files/final_biobert_output_1020notes.csv', columns = header, index=False)\n",
    "print(\"The output csv file is saved with predictions for the deployment notes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading output_csv file to see if its saved correctly\n",
    "\n",
    "deploy_results =pd.read_csv('/home/jupyter/sonam/final_result_files/final_biobert_output_1020notes.csv') \n",
    "deploy_results.shape"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
